---
title: "Project 1 Spotify Churn Data Science Laura Escher"
author: "Laura Escher"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r setup, include=FALSE}
# Some of common RMD options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(results="markup", warning = F, message = F)
options(scientific=T, digits = 3) 
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r - Investigating the data set variables}
library(ggplot2)
library(dplyr)

spotify <- read.csv("C:/Users/esche/OneDrive - The George Washington University/Intro to Data Science/Data Science Project 1/spotify_churn_dataset.csv")

str(spotify)

colSums(is.na(spotify))

nrow(spotify)

#sum(spotify$gender=='Male')
```
I first opened up the file and examined the data using the str() function. I checked to see if there are any missing values in the data, which there are none. There are 8000 observations in this data set, and 12 variables. The variables are:

Variable  |  Definition

user_id | Unique identifier for each user
gender | User gender (Male/Female/Other)
age | User age
country | User location
subscription_type | Type of Spotify subscription (Free, Premium, Family, Student)
listening_time | Minutes spent listening per day
songs_played_per_day | Number of songs played daily
skip_rate | Percentage of songs skipped
device_type | Device used (Mobile, Desktop, Web)
ads_listened_per_week | Number of ads heard per week
offline_listening | Offline mode usage (indicator variable. 0 for no offline mode usage, 1 for offline mode usage)
is_churned (indicator variable. 0 for no churn, 1 for churn)

The SMART question that I would like to consider is, "Do free users churn at a higher rate compared to premium, family, or student users?" To accomplish this goal, I will perform EDA on this portion of the data.

#EDA for Subscription Type
```{r}
spotify$subscription_type <- as.factor(spotify$subscription_type)
summary(spotify$subscription_type)

summary(spotify)
```
Now, let's calculate the sample percentage of users who churned based on subscription type as part of our descriptive statistics.
```{r}
spotify %>%
  group_by(subscription_type) %>%
  summarise(
    n=n(),
    mean_churn = mean(is_churned)*100)
```
Here, I create subscription type as a factor variable so I can count how many of each type of subscription are in the data set. The highest subscription type is Premium, followed by Free, Student, and Family with the lowest. The chart helps us clearly see the number of users in each subscription type and their mean churn rate (in percentage terms).

Since we want to compare free users against the other types, let's subset the data to compare. We am interested to see how they compare with their confidence intervals and a graph.

```{r}
free.spotify <- subset(spotify, spotify$subscription_type=="Free")
paid.spotify <- subset(spotify, spotify$subscription_type!="Free")
```

```{r}
t.test(free.spotify$is_churned, conf.level = 0.90)
t.test(paid.spotify$is_churned, conf.level = 0.90)

t.test(free.spotify$is_churned, paid.spotify$is_churned, conf.level = 0.90)
```
We examined them individually in a one sample t test, then together in a two sample t test. After examining the confidence intervals at the 90% confidence level, we do not see a statistically significant difference from zero with free users versus paid users on whether a given user would churn ([0.233, 0.265] and [0.253, 0.271]). With the two sample t-test, the p-value is 0.3, and we would fail to reject this at standard significance levels. This means that free users do not differ significantly in their churn rate versus paid users.

Let's make a comparison across all the groups to highlight how they are not statistically different from one another using a graph.

```{r}
ggplot(spotify, aes(x = subscription_type, y = is_churned, fill = subscription_type)) +
  stat_summary(fun = mean, geom = "bar", width = 0.6) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.2, conf.int = 0.90) +
  labs(
    x = "Subscription Type",
    y = "Mean Churn Rate",
    title = "Churn Rate by Subscription Type"
  ) +
  theme_minimal()
```

Now that we have identified that each subscription type and churn do not have a statistically significant relationship at the 10% significance level, we performed some chi square tests of independence on subscription type and other categorical variables in our data set to confirm our results.

```{r Chi Square Test to Verify Independence of Categorical Variables}
categorical_vars <- c("gender", "subscription_type", "country", "device_type", "offline_listening")

for(var in categorical_vars) {
  test_result <- chisq.test(spotify[[var]], spotify$is_churned)
  
  if(test_result$p.value < 0.10) {
    cat(var, "- SIGNIFICANT (p =", test_result$p.value, ")\n")
  } else {
    cat(var, "- NOT significant (p =", test_result$p.value, ")\n")
  }
}
```
After running the chi-square tests for independence to examine the relationship between each categorical variable and churn, we did not find statistically significant results at the 10% significance level. When examined individually, gender, subscription_type, country, device_type, and offline_listening did not show a significant association with whether a given user will churn.

What if the number of songs played per day and a user's subscription type has something to do with whether they will churn? We investigate below.

```{r Max and Min of Songs Played Per Day}
max(spotify$songs_played_per_day)
min(spotify$songs_played_per_day)
```
The minimum number of songs played per day are 1 and the maximum songs played per day are 99. There might be a relationship here! First, let's test whether songs played per day has a relationship with whether someone churns.
```{r which test to choose?}
chisq.test(spotify$songs_played_per_day, spotify$is_churned)

#t.test(spotify$songs_played_per_day, spotify$is_churned, conf.level = 0.90)
```
With a p-value of 0.09, we find evidence that songs played per day has a statistically significant relationship with whether a given user will churn. This means that the number of songs a given user plays will affect their decision to churn.

To investigate a little further with the impact of songs played per day, we created a new factor variable called listening_category. We are interested in examining whether there are any relationships among churn with different intensities of song listeners.
```{r}
spotify$listening_category <- cut(spotify$songs_played_per_day,
                                   breaks = c(1, 33, 66, 99),
                                   labels = c("Low", "Medium", "High"),
                                   include.lowest = TRUE)
summary(spotify$listening_category)
class(spotify$listening_category)
```
There are 2627 low listeners, 2706 medium listeners, and 2667 high listeners. Now, let's compare them across subscription type and their listening habits and see which one churned the most.
```{r}
tapply(spotify$is_churned==1, 
       list(spotify$subscription_type, spotify$listening_category), 
       mean)
```
After looking at the chart, we can see that family plan users who had low listening churned the most at 29.3%. Student plan users with low listening churned the least at 23.9%. However, is this statistically significant, or are any of these results statistically significant? We start with a box plot and bar chart of the songs played per day or listening categories from the lens of subscription type.
```{r}
ggplot(spotify, aes(x = subscription_type, y = songs_played_per_day)) +
  geom_boxplot() +
  labs(
    title = "Songs Played Per Day by Subscription Type",
    x = "Subscription Type",
    y = "Songs Played Per Day",
  ) +
  theme_minimal()

ggplot(spotify, aes(x = listening_category, fill = subscription_type)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Distribution of Listening Categories by Subscription Type",
    x = "Listening Category",
    y = "Number of Users in Listening Category",
    fill = "Subscription Plan"
  ) +
  theme_minimal()
```

After looking at both of these graphs, it appears that songs played per day by subscription type does not differ very much and the box plots overlap, indicating a lack of statistical significance. When it comes to the bar chart, binning different listening habits did not seem to reveal a difference between each plan that much upon first glance. Running some statistical tests will confirm our thinking. I will also perform a chi squared test of independence for listening category and churn.
```{r}
chisq.test(spotify$listening_category, spotify$is_churned)
chisq.test(spotify$listening_category, spotify$subscription_type)
```
The chi-squared test for independence reveals with a p-value of 0.2 that listening_category and subscription_type are not statistically significant from each other, meaning they are independent. We fail to reject the null hypothesis that they are independent.

Regarding the independence of listening category and churn, once again, these variables are independent of each other at a p-value of 1. Again, we fail to reject the null hypothesis that they are independent.

What if we interact listening_category with subscription type, and number of songs played with subscription type, then compared those statistical tests?

```{r}
spotify$listen_sub_interact <- interaction(spotify$listening_category, spotify$subscription_type)
chisq.test(spotify$listen_sub, spotify$is_churned)
```
With a p-value of 0.6, the results are not statistically significant and these variables are independent from one another.
```{r}
spotify$numsongs_sub_interact <- interaction(spotify$songs_played_per_day, spotify$subscription_type)
chisq.test(spotify$numsongs_sub_interact, spotify$is_churned)
```
With a p-value of 0.8, the results are once again not statistically significant and these variables are independent from one another.